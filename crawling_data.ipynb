{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b4c57b1-1354-4262-8dae-9715e6d81265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eb796a3-917a-4dcc-adac-02aa4a32c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_project(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        print(\"Creating project\", directory)\n",
    "        os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdaa2992-a26f-4da6-9491-cfedca4cd790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(file_name,content):\n",
    "    with open (file_name, 'w') as f:\n",
    "        f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0319cab5-ff83-4980-b493-0ae58d4529fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file(project_name,base_url):\n",
    "    queue = project_name + '_queue.txt'\n",
    "    crawled = project_name + '_crawled.txt'\n",
    "    if not os.path.isfile(queue):\n",
    "        write_file(queue, base_url)\n",
    "    if not os.path.isfile(crawled):\n",
    "        write_file(crawled,'')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6ec1456-cc24-471a-9a13-79b9064aac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_file(path,data):\n",
    "    with open (path,'a') as f:\n",
    "        f.write(data + '\\n')\n",
    "def delete_file_content(path):\n",
    "    with open (path,'w') as f:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "409940be-f8f4-4682-a20d-2071443c6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import parse\n",
    "from html.parser import HTMLParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4dba6aca-048d-4d9e-aff8-9400d3445b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinkFinder(HTMLParser):\n",
    "    def __init__(self,base_url,page_url):\n",
    "        super().__init__()\n",
    "        self.base_url = base_url\n",
    "        self.page_url = page_url\n",
    "        self.links = set()\n",
    "    def handle_starttag(self,tag,attrs):\n",
    "        if tag == 'a':\n",
    "            for (attribute,value) in attrs:\n",
    "                if attribute == 'href':\n",
    "                    url = parse.urljoin(self.base_url,value)\n",
    "                    self.links.add(url)\n",
    "    def page_links(self):\n",
    "        return self.links\n",
    "    def error(self,message):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51fd8bb1-4725-4ec7-be49-dc33fb2df04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_set(file_name):\n",
    "    result = set()\n",
    "    with open (file_name, 'rt') as f:\n",
    "        for line in f:\n",
    "            result.add(line.replace('\\n',''))\n",
    "        return result\n",
    "def set_to_file(links,file):\n",
    "    delete_file_content(file)\n",
    "    for link in sorted(links):\n",
    "        append_to_file(file,link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "169be05c-3045-4596-8fb8-d9054f8cc7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "def get_sub_domain_name(url):\n",
    "    try:\n",
    "        return urlparse(url).netloc\n",
    "    except:\n",
    "        return \"\"\n",
    "def get_domain_name(url):\n",
    "    try:\n",
    "        results = get_sub_domain_name(url).split('.')\n",
    "        return results[-2] + '.' + results[-1]\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0e76a4df-7d53-433a-8037-89bf80820a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "class Spider():\n",
    "    project_name = ''\n",
    "    base_url = ''\n",
    "    domain_name = ''\n",
    "    queue_file = ''\n",
    "    crawled_file = ''\n",
    "    queue = set()\n",
    "    crawled = set()\n",
    "    def __init__ (self,project_name, base_url,domain_name):\n",
    "        Spider.project_name = project_name\n",
    "        Spider.base_url = base_url\n",
    "        Spider.domain_name = domain_name\n",
    "        Spider.queue_file = Spider.project_name + 'queue.txt'\n",
    "        Spider.crawled_file = Spider.project_name + 'crawled.txt'\n",
    "        self.boot()\n",
    "        self.crawl_page('First spider',Spider.base_url)\n",
    "    @staticmethod\n",
    "    def boot():\n",
    "        create_project(Spider.project_name)\n",
    "        create_file(Spider.project_name,Spider.base_url)\n",
    "        Spider.queue = file_to_set(Spider.queue_file)\n",
    "        Spider.crawled = file_to_set(Spider.crawled_file)\n",
    "    @staticmethod\n",
    "    def crawl_page(thread_name,page_url):\n",
    "        if page_url not in Spider.crawled:\n",
    "            print (thread_name + 'not crawling' + page_url)\n",
    "            print ( 'Queue' + str(len(Spider.queue)) + ' | crawled '+ str(len(Spider.crawled)))\n",
    "            Spider.add_link_to_queue(Spider.gather_link(page_url))\n",
    "            Spider.queue.remove(page_url)\n",
    "            Spider.crawled.add(page_url)\n",
    "            Spider.update_files()\n",
    "    @staticmethod\n",
    "    def gather_links(page_url):\n",
    "        html_string = ''\n",
    "        try:\n",
    "            response = urlopen(page_url)\n",
    "            if response.getheader('Content-Type') == 'text/html':\n",
    "                html_bytes = response.read()\n",
    "                html_string = html_bytes.decode('utf-8')\n",
    "            finder = LinkFinder(Spider.base_url,page_url)\n",
    "            finder.feed(html_string)\n",
    "        except:\n",
    "            print ('Error: can not crawl page')\n",
    "            return set()\n",
    "        return finder.page_links()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "148c7f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating project thenewboston\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'thenewbostonqueue.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m number_of_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m\n\u001b[0;32m      7\u001b[0m queue \u001b[38;5;241m=\u001b[39m Queue()\n\u001b[1;32m----> 8\u001b[0m \u001b[43mSpider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43mhomepage\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdomain_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[40], line 16\u001b[0m, in \u001b[0;36mSpider.__init__\u001b[1;34m(self, project_name, base_url, domain_name)\u001b[0m\n\u001b[0;32m     14\u001b[0m Spider\u001b[38;5;241m.\u001b[39mqueue_file \u001b[38;5;241m=\u001b[39m Spider\u001b[38;5;241m.\u001b[39mproject_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqueue.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     15\u001b[0m Spider\u001b[38;5;241m.\u001b[39mcrawled_file \u001b[38;5;241m=\u001b[39m Spider\u001b[38;5;241m.\u001b[39mproject_name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcrawled.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcrawl_page(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst spider\u001b[39m\u001b[38;5;124m'\u001b[39m,Spider\u001b[38;5;241m.\u001b[39mbase_url)\n",
      "Cell \u001b[1;32mIn[40], line 22\u001b[0m, in \u001b[0;36mSpider.boot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m create_project(Spider\u001b[38;5;241m.\u001b[39mproject_name)\n\u001b[0;32m     21\u001b[0m create_file(Spider\u001b[38;5;241m.\u001b[39mproject_name,Spider\u001b[38;5;241m.\u001b[39mbase_url)\n\u001b[1;32m---> 22\u001b[0m Spider\u001b[38;5;241m.\u001b[39mqueue \u001b[38;5;241m=\u001b[39m \u001b[43mfile_to_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSpider\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueue_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m Spider\u001b[38;5;241m.\u001b[39mcrawled \u001b[38;5;241m=\u001b[39m file_to_set(Spider\u001b[38;5;241m.\u001b[39mcrawled_file)\n",
      "Cell \u001b[1;32mIn[12], line 3\u001b[0m, in \u001b[0;36mfile_to_set\u001b[1;34m(file_name)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfile_to_set\u001b[39m(file_name):\n\u001b[0;32m      2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f:\n\u001b[0;32m      5\u001b[0m             result\u001b[38;5;241m.\u001b[39madd(line\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'thenewbostonqueue.txt'"
     ]
    }
   ],
   "source": [
    "project_name = 'thenewboston'\n",
    "homepage = 'https://thenewboston.com/'\n",
    "domain_name = get_domain_name(homepage)\n",
    "queue_file = project_name + 'queue.txt'\n",
    "crawled_file = project_name + 'crawled.txt'\n",
    "number_of_threads = 8\n",
    "queue = Queue()\n",
    "Spider(project_name,homepage,domain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cb9e1422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from queue import Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ede2db24",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'thenewboston'\n",
    "homepage = 'https://thenewboston.com/'\n",
    "domain_name = get_domain_name(homepage)\n",
    "queue_file = project_name + 'queue.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73594b1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thenewbostonqueue.txt'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e597e68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d91060-b99f-460c-a05b-057e905d7531",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f848e61-0751-4c67-b00c-ca270f305913",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c01e4c-9fff-483e-8bef-c3ff4cf5aa45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
